# Building a Large Language Model *from scratch*
This project is based on the book "**Build a Large Language Model (from scratch)** by *Sebastian Raschka*". 

üìù The project's objectives includes the following:
- A Working GPT-style Large Language Model
- End-to-End Pretraining Pipeline
- Fine-Tuned Model for Practical Tasks

<br>



**Components:**
1. Tokenization
2. Embeddings Model
3. Multi-Head Self- Attention Mechanism
4. Transformer Block
5. Decoding Loop



### TL;DR: The code implementation of each chapter can be found on the respective labelled notebooks, however if you want to dive directly into the final product, the final GPT model is implemented on the "GPTModel" notebook.

---
## Project Guide
![image](Images\Build-LLMS-from-scratch.png)
This is the structure by which the project follows, each divided into 3 stages, the sub-stages are seperated by folders specifying which chapters are dealing with which stage.



