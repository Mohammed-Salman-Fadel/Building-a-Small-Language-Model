# Stage One : Focus
This Stage is all about defining the core components of LLMs, such as *the tokenizer, attention mechanisms and final GPT model.*

Each notebook contains not only the final code, instead there's progressive demostrations as you follow the notebook, highlighting each step necessary to achieve the final outcome, including comments, images and guides along the way.

<br>

Here's the order of notebooks to best understand how LLMs works:
1. *"tokenizer"* - provides intuition and creates a simple tokenizer.
2. *"attention"* - the code for the original and progressive attention mechanisms.
3. *"llm"* - combines all the previous steps to get our final GPT model.